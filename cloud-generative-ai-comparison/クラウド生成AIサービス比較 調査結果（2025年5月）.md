# クラウド生成 AI サービス比較 調査結果（2025 年 5 月）

## 1. 調査目的

主要なクラウド生成 AI サービスを対象に、性能、価格、日本語対応、長文処理能力などの観点で比較し、用途に応じた選定の指針を得る。

## 2. 比較対象と構成

以下の 7 モデルを中心に調査を実施。

| サービス名  | モデル名        | 提供元          |
| ----------- | --------------- | --------------- |
| OpenAI      | GPT-4o          | OpenAI          |
| Anthropic   | Claude 3 Opus   | Anthropic       |
| Google      | Gemini 1.5 Pro  | Google DeepMind |
| Mistral     | Mistral Large 2 | Mistral AI      |
| Meta / Groq | Llama 3 70B     | Meta / Groq     |
| Perplexity  | Sonar Pro       | Perplexity AI   |
| Inflection  | Pi              | Inflection AI   |

---

## 3. 比較表（要点）

### モデル性能・対応力比較

| モデル          | 推論能力（MMLU 等）          | 最大トークン長 | 日本語対応   | コーディング性能      |
| --------------- | ---------------------------- | -------------- | ------------ | --------------------- |
| GPT-4o          | 非常に高い（MMLU 82）        | 128K           | 高精度       | HumanEval 88%         |
| Claude 3 Opus   | 非常に高い（MMLU 80 以上）   | 200K           | 非常に高精度 | 高精度                |
| Gemini 1.5 Pro  | 高い（MMLU 80 前後）         | 最大 1M        | 高精度       | 高精度                |
| Mistral Large 2 | 中程度（MMLU 70 台）         | 128K           | 中程度       | 中程度                |
| Llama 3 70B     | 中程度                       | 128K           | 中程度       | 高精度（Groq 環境下） |
| Sonar Pro       | 高精度（マルチステップ対応） | 非公開         | 高精度       | 中程度                |
| HeyPi           | 中程度（対話特化）           | 非公開         | 高精度       | 非対応                |

### 価格（API 利用）

| モデル          | 入力/出力 1K tokens 単価（USD） |
| --------------- | ------------------------------- |
| GPT-4o          | $0.03 / $0.06                   |
| Claude 3 Opus   | $0.015 / $0.075                 |
| Gemini 1.5 Pro  | $0.0375 / $0.15（128K 以下）    |
| Mistral Large 2 | $0.003 / $0.009                 |
| Llama 3 70B     | $0.00059 / $0.00079             |
| Sonar Pro       | $0.003 / $0.015                 |
| HeyPi           | 無料（API 未提供）              |

---

## 4. 実地評価と所感

| 観点           | 評価モデル例               | 備考                     |
| -------------- | -------------------------- | ------------------------ |
| レスポンス速度 | Llama 3.1（Groq）          | 非常に高速               |
| 創造性・一貫性 | GPT-4o, Claude 3 Opus      | 高い応答の安定性と創造性 |
| 日本語表現力   | Claude 3 Opus              | 最も自然かつ高度な応答   |
| 長文対応       | Gemini 1.5 Pro（1M token） | 文書要約や対話に最適     |
| コーディング   | Llama 3.1 405B, GPT-4o     | HumanEval 89%、88%       |

---

## 5. 用途別推奨モデル

| 用途                     | 推奨モデル                         |
| ------------------------ | ---------------------------------- |
| 高速な応答               | Llama 3.1（Groq）, Mistral Large 2 |
| 高精度な日本語対応       | Claude 3 Opus, GPT-4o, Llama 3.1   |
| 高度なコーディング支援   | Llama 3.1 405B, GPT-4o             |
| 大規模文書・長文処理     | Gemini 1.5 Pro, Claude 3 Opus      |
| パーソナル対話・感情対応 | HeyPi（Inflection AI）             |

---

## 6. 総評と結論

- **Claude 3 Opus** は日本語表現力に優れた高性能 LLM で、対話・要約・翻訳に強い
- **GPT-4o** は高精度・高汎用性のバランスが取れた万能型で、API も安定
- **Gemini 1.5 Pro** は超長文処理やマルチモーダル処理に強み
- **Mistral / Llama 3（Groq）** はコストパフォーマンスや高速性が特徴
- **Sonar Pro** は検索・要約を組み合わせた新しいユースケースに向く
- **HeyPi** は API 提供こそ無いが、対話品質と反応の自然さで特化型の価値がある

---

## 7. 今後の検討課題

- API 連携実験（呼び出し速度・トークン消費・JSON 処理）
- 独自ユースケースとの統合検証（社内 FAQ、ソースコードレビュー等）
- 日本語長文生成・読み込みテストの継続
- 商用利用時の利用規約・ライセンス範囲の比較
